import requests
import pandas as pd
from bs4 import BeautifulSoup
from datetime import datetime


def crawl_7eleven():
    print("ğŸš€ ì„¸ë¸ì¼ë ˆë¸ ë°ì´í„° ìˆ˜ì§‘ì„ ì‹œì‘í•©ë‹ˆë‹¤... (Ajax ì§ì ‘ ìš”ì²­ ë°©ì‹)")

    all_products = []
    # pTab 1: 1+1, pTab 2: 2+1
    event_configs = [(1, "1+1"), (2, "2+1")]

    # ì‹¤ì œ ë°ì´í„°ê°€ ìš”ì²­ë˜ëŠ” URL (ì´ë¯¸ì§€ ë¡œê·¸ í™•ì¸ ê²°ê³¼)
    url = "https://www.7-eleven.co.kr/product/listMoreAjax.asp"

    headers = {
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/122.0.0.0 Safari/537.36",
        "Content-Type": "application/x-www-form-urlencoded; charset=UTF-8",
        "Referer": "https://www.7-eleven.co.kr/product/presentList.asp"
    }

    for p_tab, event_label in event_configs:
        print(f"ğŸ“¦ {event_label} ìƒí’ˆ ê°€ì ¸ì˜¤ëŠ” ì¤‘...")

        # intPageSizeë¥¼ í¬ê²Œ ì¡ì•„ì„œ MORE ë²„íŠ¼ í´ë¦­ ì—†ì´ í•œ ë²ˆì— ë‹¤ ê°€ì ¸ì˜¤ê¸°
        payload = {
            "intPageSize": 1000000,
            "pTab": p_tab,
            "currPage": 1
        }

        try:
            response = requests.post(url, headers=headers, data=payload)
            if response.status_code == 200:
                soup = BeautifulSoup(response.text, 'html.parser')
                # ìƒí’ˆ ë¦¬ìŠ¤íŠ¸ëŠ” li íƒœê·¸ë¡œ êµ¬ì„±ë¨
                items = soup.select("li")

                for item in items:
                    try:
                        # 1. ìƒí’ˆëª… (alt ì†ì„±ì´ë‚˜ txt_product í´ë˜ìŠ¤)
                        img_tag = item.select_one(".pic_product img")
                        name = img_tag.get('alt', '').strip() if img_tag else item.select_one(".txt_product").get_text(
                            strip=True)

                        # 2. ê°€ê²© (ìˆ«ìë§Œ ì¶”ì¶œ)
                        price_text = item.select_one(".price_list span").get_text(strip=True).replace(',', '')
                        price = int(price_text)

                        # 3. í–‰ì‚¬ ì¢…ë¥˜ (ì´ë¯¸ì§€ ë¡œê·¸ ìƒì˜ íƒœê·¸)
                        event = item.select_one(".tag_list_01 li").get_text(strip=True)

                        # 4. ì´ë¯¸ì§€ ì£¼ì†Œ
                        img_src = img_tag.get('src')
                        img_url = f"https://www.7-eleven.co.kr{img_src}"

                        all_products.append({
                            "brand": "7Eleven",
                            "name": name,
                            "price": price,
                            "event": event,
                            "img_url": img_url
                        })
                    except Exception:
                        continue
        except Exception as e:
            print(f"âŒ {event_label} ìˆ˜ì§‘ ì¤‘ ì˜¤ë¥˜: {e}")

    # 2. ì €ì¥ í˜•ì‹ (CSV, utf-8-sig, í¸ì˜ì ëª…_ë‚ ì§œ.csv)
    if all_products:
        df = pd.DataFrame(all_products)
        df = df[["brand", "name", "price", "event", "img_url"]]  # ì—´ ì´ë¦„ ë° ìˆœì„œ ê³ ì •

        today = datetime.now().strftime("%y%m%d")
        file_name = f"7Eleven_{today}.csv"

        df.to_csv(file_name, index=False, encoding='utf-8-sig')

        print("\n" + "=" * 40)
        print(f"ğŸ‰ ìˆ˜ì§‘ ì„±ê³µ! íŒŒì¼ì´ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.")
        print(f"ğŸ“„ íŒŒì¼ëª…: {file_name}")
        print(f"ğŸ“Š ì´ ìƒí’ˆ ìˆ˜: {len(all_products)}ê°œ")
        print("=" * 40)
    else:
        print("âŒ ìˆ˜ì§‘ëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ë‹¤ì‹œ í™•ì¸í•´ ì£¼ì„¸ìš”.")


if __name__ == "__main__":
    crawl_7eleven()